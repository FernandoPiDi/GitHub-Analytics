{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Use python-dotenv to load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from langchain.globals import set_verbose, set_debug\n",
    "\n",
    "# set_verbose(True)\n",
    "# set_debug(True)\n",
    "\n",
    "# Add the src directory to Python path\n",
    "src_path = str(Path.cwd().parent / \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import get_settings\n",
    "\n",
    "settings = get_settings()\n",
    "settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the full graph\n",
    "# Create agents\n",
    "import uuid\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "from services.agents.analyst import ANALYST_SYSTEM_MESSAGE, DataAnalystAgent\n",
    "from services.agents.developer import DEVELOPER_SYSTEM_MESSAGE, DeveloperAgent\n",
    "from services.agents.graph import create_agent_graph\n",
    "from services.agents.planner import PLANNER_SYSTEM_MESSAGE, PlannerAgent\n",
    "from services.agents.supervisor import SUPERVISOR_SYSTEM_MESSAGE, SupervisorAgent\n",
    "from services.agents.tools import (\n",
    "    GetRepoCommitsTool,\n",
    "    GetRepoIssuesTools,\n",
    "    GetRepoPullRequestsTool,\n",
    ")\n",
    "from services.gql.client import Client\n",
    "\n",
    "client = Client(\n",
    "    url=str(settings.github_graphql_url),\n",
    "    headers={\"Authorization\": settings.codegen_gh_auth.get_secret_value()},\n",
    ")\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=settings.azure_openai_api_version,\n",
    "    azure_endpoint=settings.azure_openai_endpoint,\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=settings.azure_openai_api_key.get_secret_value(),\n",
    ")\n",
    "\n",
    "llm_mini = AzureChatOpenAI(\n",
    "    api_version=settings.azure_openai_api_version,\n",
    "    azure_endpoint=settings.azure_openai_endpoint,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=settings.azure_openai_api_key.get_secret_value(),\n",
    ")\n",
    "\n",
    "supervisor = SupervisorAgent(\n",
    "    llm=llm_mini,\n",
    "    tools=[],\n",
    "    system_message=SUPERVISOR_SYSTEM_MESSAGE,\n",
    "    team_members=[\"planner\", \"analyst\", \"developer\"],\n",
    ")\n",
    "\n",
    "planner = PlannerAgent(\n",
    "    llm=llm,\n",
    "    tools=[],\n",
    "    system_message=PLANNER_SYSTEM_MESSAGE,\n",
    ")\n",
    "\n",
    "analyst_tools = [\n",
    "    GetRepoIssuesTools(client=client),\n",
    "    GetRepoCommitsTool(client=client),\n",
    "    GetRepoPullRequestsTool(client=client),\n",
    "]\n",
    "analyst = DataAnalystAgent(\n",
    "    llm=llm,\n",
    "    tools=analyst_tools,\n",
    "    system_message=ANALYST_SYSTEM_MESSAGE,\n",
    ")\n",
    "\n",
    "developer = DeveloperAgent(\n",
    "    llm=llm,\n",
    "    tools=[],\n",
    "    system_message=DEVELOPER_SYSTEM_MESSAGE,\n",
    ")\n",
    "\n",
    "# Create the graph\n",
    "graph = create_agent_graph(supervisor, planner, analyst, developer)\n",
    "\n",
    "# Initialize the context\n",
    "context = {\n",
    "    \"message\": \"Create a line chart showing the number of commits over time\",\n",
    "    \"owner\": \"langchain-ai\",\n",
    "    \"repo\": \"langchain\",\n",
    "    \"chat_history\": [\n",
    "        HumanMessage(\n",
    "            id=str(uuid.uuid4()),\n",
    "            content=\"Create a line chart showing the number of commits over time\",\n",
    "            name=\"user\",\n",
    "        )\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Execute the graph\n",
    "final_context = graph.invoke(context)\n",
    "\n",
    "print(final_context[\"developer_output\"].typescript_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = [\n",
    "    {\n",
    "        \"committed_date\": \"2024-11-06T20:04:09Z\",\n",
    "        \"authored_date\": \"2024-11-06T20:04:09Z\",\n",
    "        \"author\": \"Eric Pinzur\",\n",
    "        \"message\": \"community: added Document.id support to opensearch vectorstore (#27945)\\n\\nDescription:\\r\\n* Added support of Document.id on OpenSearch vector store\\r\\n* Added tests cases to match\",\n",
    "        \"changed_files_if_available\": 2,\n",
    "        \"additions\": 55,\n",
    "        \"deletions\": 21,\n",
    "        \"status\": \"SUCCESS\",\n",
    "    },\n",
    "    {\n",
    "        \"committed_date\": \"2024-11-06T19:55:00Z\",\n",
    "        \"authored_date\": \"2024-11-06T19:55:00Z\",\n",
    "        \"author\": \"Hammad Randhawa\",\n",
    "        \"message\": 'docs: Completed sentence under the heading  \"Instantiating a Browser … (#27944)\\n\\n…Toolkit\" in \"playwright.ipynb\" integration.\\r\\n\\r\\n- Completed the incomplete sentence in the Langchain Playwright\\r\\ndocumentation.\\r\\n\\r\\n- Enhanced documentation clarity to guide users on best practices for\\r\\ninstantiating browser instances with Langchain Playwright.\\r\\n\\r\\nExample before:\\r\\n> \"It\\'s always recommended to instantiate using the from_browser method\\r\\nso that the\\r\\n\\r\\nExample after:\\r\\n> \"It\\'s always recommended to instantiate using the `from_browser`\\r\\nmethod so that the browser context is properly initialized and managed,\\r\\nensuring seamless interaction and resource optimization.\"\\r\\n\\r\\nCo-authored-by: Erick Friis <erick@langchain.dev>',\n",
    "        \"changed_files_if_available\": 1,\n",
    "        \"additions\": 1,\n",
    "        \"deletions\": 1,\n",
    "        \"status\": \"SUCCESS\",\n",
    "    },\n",
    "    {\n",
    "        \"committed_date\": \"2024-11-06T18:06:47Z\",\n",
    "        \"authored_date\": \"2024-11-06T18:06:47Z\",\n",
    "        \"author\": \"Bagatur\",\n",
    "        \"message\": \"core[patch]: make oai tool description optional (#27756)\",\n",
    "        \"changed_files_if_available\": 2,\n",
    "        \"additions\": 174,\n",
    "        \"deletions\": 23,\n",
    "        \"status\": \"SUCCESS\",\n",
    "    },\n",
    "    {\n",
    "        \"committed_date\": \"2024-11-06T17:50:07Z\",\n",
    "        \"authored_date\": \"2024-11-06T17:50:07Z\",\n",
    "        \"author\": \"Bagatur\",\n",
    "        \"message\": \"docs: document init_chat_model standard params (#27812)\",\n",
    "        \"changed_files_if_available\": 1,\n",
    "        \"additions\": 10,\n",
    "        \"deletions\": 1,\n",
    "        \"status\": \"SUCCESS\",\n",
    "    },\n",
    "    {\n",
    "        \"committed_date\": \"2024-11-06T14:58:16Z\",\n",
    "        \"authored_date\": \"2024-11-06T14:58:16Z\",\n",
    "        \"author\": \"Dobiichi-Origami\",\n",
    "        \"message\": \"community: re-arrange function call message parse logic for Qianfan (#27935)\\n\\nthe [PR](https://github.com/langchain-ai/langchain/pull/26208) two month\\r\\nago has a potential bug which causes malfunction of `tool_call` for\\r\\n`QianfanChatEndpoint` waiting for fix\",\n",
    "        \"changed_files_if_available\": 1,\n",
    "        \"additions\": 3,\n",
    "        \"deletions\": 7,\n",
    "        \"status\": \"SUCCESS\",\n",
    "    },\n",
    "    {\n",
    "        \"committed_date\": \"2024-11-06T00:43:11Z\",\n",
    "        \"authored_date\": \"2024-11-06T00:43:11Z\",\n",
    "        \"author\": \"Erick Friis\",\n",
    "        \"message\": \"infra: starter codeowners file (#27929)\",\n",
    "        \"changed_files_if_available\": 1,\n",
    "        \"additions\": 2,\n",
    "        \"deletions\": 0,\n",
    "        \"status\": \"SUCCESS\",\n",
    "    },\n",
    "    {\n",
    "        \"committed_date\": \"2024-11-05T23:02:24Z\",\n",
    "        \"authored_date\": \"2024-11-05T23:02:24Z\",\n",
    "        \"author\": \"ccurme\",\n",
    "        \"message\": \"openai[patch]: release 0.2.6 (#27924)\\n\\nSome additions in support of [predicted\\r\\noutputs](https://platform.openai.com/docs/guides/latency-optimization#use-predicted-outputs)\\r\\nfeature:\\r\\n- Bump openai sdk version\\r\\n- Add integration test\\r\\n- Add example to integration docs\\r\\n\\r\\nThe `prediction` kwarg is already plumbed through model invocation.\",\n",
    "        \"changed_files_if_available\": 4,\n",
    "        \"additions\": 150,\n",
    "        \"deletions\": 12,\n",
    "        \"status\": \"SUCCESS\",\n",
    "    },\n",
    "    {\n",
    "        \"committed_date\": \"2024-11-05T20:55:38Z\",\n",
    "        \"authored_date\": \"2024-11-05T20:55:38Z\",\n",
    "        \"author\": \"Erick Friis\",\n",
    "        \"message\": \"standard-tests: ci pipeline (#27923)\",\n",
    "        \"changed_files_if_available\": 5,\n",
    "        \"additions\": 71,\n",
    "        \"deletions\": 7,\n",
    "        \"status\": \"SUCCESS\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "from services.agents.developer import DEVELOPER_SYSTEM_MESSAGE, DeveloperAgent\n",
    "from services.agents.types import AnalystOutput, PlannerOutput, TechnicalSpecs\n",
    "from services.gql.client import Client\n",
    "\n",
    "client = Client(\n",
    "    url=str(settings.github_graphql_url),\n",
    "    headers={\"Authorization\": settings.codegen_gh_auth.get_secret_value()},\n",
    ")\n",
    "\n",
    "# Create the array of tools, that contains the tools for the analyst agent\n",
    "# He should be able to query GitHub issues, Pull requests, and commits\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=settings.azure_openai_api_version,\n",
    "    azure_endpoint=settings.azure_openai_endpoint,\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=settings.azure_openai_api_key.get_secret_value(),\n",
    ")\n",
    "\n",
    "# Initialize the planner agent\n",
    "developer = DeveloperAgent(\n",
    "    llm=llm,\n",
    "    system_message=DEVELOPER_SYSTEM_MESSAGE,\n",
    "    tools=[],\n",
    ")\n",
    "\n",
    "# Test context\n",
    "context = {\n",
    "    \"message\": \"Create a line chart showing the number of commits over time\",\n",
    "    \"owner\": \"langchain-ai\",\n",
    "    \"repo\": \"langchain\",\n",
    "    \"planner_output\": PlannerOutput(\n",
    "        requirements=[\n",
    "            \"The system shall generate a line chart displaying the number of commits over time.\",\n",
    "            \"The data shall be fetched from the GitHub repository langchain-ai/langchain.\",\n",
    "            \"The user shall be able to specify the time range for which the data is displayed.\",\n",
    "            \"The chart shall update dynamically as new commits are made.\",\n",
    "        ],\n",
    "        acceptance_criteria=[],\n",
    "        technical_specs=TechnicalSpecs(\n",
    "            chart_type=\"line\", data_format=\"\", technical_constraints=[]\n",
    "        ),\n",
    "        error_message=None,\n",
    "    ),\n",
    "    \"analyst_output\": AnalystOutput(\n",
    "        data_sample=data_sample,\n",
    "        file_path=\"../data/langchain-ai/langchain/data.json\",\n",
    "        error_message=None,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Execute the agent\n",
    "result = await developer.execute(context)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "from services.agents.analyst import ANALYST_SYSTEM_MESSAGE, DataAnalystAgent\n",
    "from services.agents.tools import (\n",
    "    GetRepoCommitsTool,\n",
    "    GetRepoIssuesTools,\n",
    "    GetRepoPullRequestsTool,\n",
    ")\n",
    "from services.agents.types import PlannerOutput, TechnicalSpecs\n",
    "from services.gql.client import Client\n",
    "\n",
    "client = Client(\n",
    "    url=str(settings.github_graphql_url),\n",
    "    headers={\"Authorization\": settings.codegen_gh_auth.get_secret_value()},\n",
    ")\n",
    "\n",
    "# Create the array of tools, that contains the tools for the analyst agent\n",
    "# He should be able to query GitHub issues, Pull requests, and commits\n",
    "tools = [\n",
    "    GetRepoIssuesTools(client=client),\n",
    "    GetRepoCommitsTool(client=client),\n",
    "    GetRepoPullRequestsTool(client=client),\n",
    "]\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=settings.azure_openai_api_version,\n",
    "    azure_endpoint=settings.azure_openai_endpoint,\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=settings.azure_openai_api_key.get_secret_value(),\n",
    ")\n",
    "\n",
    "# Initialize the planner agent\n",
    "analyst = DataAnalystAgent(\n",
    "    llm=llm,\n",
    "    system_message=ANALYST_SYSTEM_MESSAGE,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "# Test context\n",
    "context = {\n",
    "    \"message\": \"Create a line chart showing the number of commits over time\",\n",
    "    \"owner\": \"langchain-ai\",\n",
    "    \"repo\": \"langchain\",\n",
    "    \"planner_output\": PlannerOutput(\n",
    "        requirements=[\n",
    "            \"The system shall generate a line chart displaying the number of commits over time.\",\n",
    "            \"The data shall be fetched from the GitHub repository langchain-ai/langchain.\",\n",
    "            \"The user shall be able to specify the time range for which the data is displayed.\",\n",
    "            \"The chart shall update dynamically as new commits are made.\",\n",
    "        ],\n",
    "        acceptance_criteria=[],\n",
    "        technical_specs=TechnicalSpecs(\n",
    "            chart_type=\"line\", data_format=\"\", technical_constraints=[]\n",
    "        ),\n",
    "        error_message=None,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Execute the agent\n",
    "result = await analyst.execute(context)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "from services.agents.planner import PLANNER_SYSTEM_MESSAGE, PlannerAgent\n",
    "from services.agents.types import PlannerOutput, TechnicalSpecs\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=settings.azure_openai_api_version,\n",
    "    azure_endpoint=settings.azure_openai_endpoint,\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=settings.azure_openai_api_key.get_secret_value(),\n",
    ")\n",
    "\n",
    "# Initialize the planner agent\n",
    "planner = PlannerAgent(llm=llm, system_message=PLANNER_SYSTEM_MESSAGE, tools=[])\n",
    "\n",
    "# Test context\n",
    "context = {\n",
    "    \"message\": \"Create a line chart showing the number of commits over time\",\n",
    "    \"owner\": \"langchain-ai\",\n",
    "    \"repo\": \"langchain\",\n",
    "}\n",
    "\n",
    "# Execute the agent\n",
    "result = planner.execute(context)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
