[{"committed_date": "2024-11-09T21:04:18Z", "authored_date": "2024-11-09T21:04:18Z", "author": "ccurme", "message": "docs: update some cassettes (#28010)", "changed_files_if_available": 5, "additions": 5, "deletions": 5, "status": "SUCCESS"}, {"committed_date": "2024-11-09T13:57:58Z", "authored_date": "2024-11-09T13:57:58Z", "author": "ccurme", "message": "docs: add cross-links (#28000)\n\nMainly to improve visibility of integration pages.", "changed_files_if_available": 5, "additions": 22, "deletions": 7, "status": "SUCCESS"}, {"committed_date": "2024-11-09T03:12:59Z", "authored_date": "2024-11-09T03:12:59Z", "author": "Bagatur", "message": "openai[patch]: default to invoke on o1 stream() (#27983)", "changed_files_if_available": 2, "additions": 46, "deletions": 36, "status": "SUCCESS"}, {"committed_date": "2024-11-08T19:51:17Z", "authored_date": "2024-11-08T19:51:17Z", "author": "Bagatur", "message": "docs: intro nit (#27998)", "changed_files_if_available": 1, "additions": 2, "deletions": 2, "status": "SUCCESS"}, {"committed_date": "2024-11-08T19:47:32Z", "authored_date": "2024-11-08T19:47:32Z", "author": "ccurme", "message": "docs: update tutorials index and add get started guides (#27996)", "changed_files_if_available": 1, "additions": 15, "deletions": 15, "status": "SUCCESS"}, {"committed_date": "2024-11-08T19:04:57Z", "authored_date": "2024-11-08T19:04:57Z", "author": "Eric Pinzur", "message": "community[patch]: Added type hinting to OpenSearch clients (#27946)\n\nDescription:\r\n* When working with OpenSearchVectorSearch to make\r\nOpenSearchGraphVectorStore (coming soon), I noticed that there wasn't\r\ntype hinting for the underlying OpenSearch clients. This fixes that\r\nissue.\r\n* Confirmed tests are still passing with code changes.\r\n\r\nNote that there is some additional code duplication now, but I think\r\nthis approach is cleaner overall.", "changed_files_if_available": 1, "additions": 39, "deletions": 65, "status": "SUCCESS"}, {"committed_date": "2024-11-08T14:40:15Z", "authored_date": "2024-11-08T14:40:15Z", "author": "Zapiron", "message": "docs: fix link in custom tools guide (#27975)\n\nFixed broken link in tools documentation for `BaseTool`", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-08T14:39:27Z", "authored_date": "2024-11-08T14:39:27Z", "author": "Zapiron", "message": "docs: fix link in tool-calling guide (#27976)\n\nFix broken BaseTool link in documentation", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "FAILURE"}, {"committed_date": "2024-11-08T14:38:32Z", "authored_date": "2024-11-08T14:38:32Z", "author": "Zapiron", "message": "docs: fix typo in PDF loader guide (#27977)\n\nFixed duplicate \"py\" in hyperlink to `pypdf` docs", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-07T23:29:35Z", "authored_date": "2024-11-07T23:29:35Z", "author": "Saad Makrod", "message": "Community: Google Books API Tool (#27307)\n\n## Description\r\n\r\nAs proposed in our earlier discussion #26977 we have introduced a Google\r\nBooks API Tool that leverages the Google Books API found at\r\n[https://developers.google.com/books/docs/v1/using](https://developers.google.com/books/docs/v1/using)\r\nto generate book recommendations.\r\n\r\n### Sample Usage\r\n\r\n```python\r\nfrom langchain_community.tools import GoogleBooksQueryRun\r\nfrom langchain_community.utilities import GoogleBooksAPIWrapper\r\n\r\napi_wrapper = GoogleBooksAPIWrapper()\r\ntool = GoogleBooksQueryRun(api_wrapper=api_wrapper)\r\n\r\ntool.run('ai')\r\n```\r\n\r\n### Sample Output\r\n\r\n```txt\r\nHere are 5 suggestions based off your search for books related to ai:\r\n\r\n1. \"AI's Take on the Stigma Against AI-Generated Content\" by Sandy Y. Greenleaf: In a world where artificial intelligence (AI) is rapidly advancing and transforming various industries, a new form of content creation has emerged: AI-generated content. However, despite its potential to revolutionize the way we produce and consume information, AI-generated content often faces a significant stigma. \"AI's Take on the Stigma Against AI-Generated Content\" is a groundbreaking book that delves into the heart of this issue, exploring the reasons behind the stigma and offering a fresh, unbiased perspective on the topic. Written from the unique viewpoint of an AI, this book provides readers with a comprehensive understanding of the challenges and opportunities surrounding AI-generated content. Through engaging narratives, thought-provoking insights, and real-world examples, this book challenges readers to reconsider their preconceptions about AI-generated content. It explores the potential benefits of embracing this technology, such as increased efficiency, creativity, and accessibility, while also addressing the concerns and drawbacks that contribute to the stigma. As you journey through the pages of this book, you'll gain a deeper understanding of the complex relationship between humans and AI in the realm of content creation. You'll discover how AI can be used as a tool to enhance human creativity, rather than replace it, and how collaboration between humans and machines can lead to unprecedented levels of innovation. Whether you're a content creator, marketer, business owner, or simply someone curious about the future of AI and its impact on our society, \"AI's Take on the Stigma Against AI-Generated Content\" is an essential read. With its engaging writing style, well-researched insights, and practical strategies for navigating this new landscape, this book will leave you equipped with the knowledge and tools needed to embrace the AI revolution and harness its potential for success. Prepare to have your assumptions challenged, your mind expanded, and your perspective on AI-generated content forever changed. Get ready to embark on a captivating journey that will redefine the way you think about the future of content creation.\r\nRead more at https://play.google.com/store/books/details?id=4iH-EAAAQBAJ&source=gbs_api\r\n\r\n2. \"AI Strategies For Web Development\" by Anderson Soares Furtado Oliveira: From fundamental to advanced strategies, unlock useful insights for creating innovative, user-centric websites while navigating the evolving landscape of AI ethics and security Key Features Explore AI's role in web development, from shaping projects to architecting solutions Master advanced AI strategies to build cutting-edge applications Anticipate future trends by exploring next-gen development environments, emerging interfaces, and security considerations in AI web development Purchase of the print or Kindle book includes a free PDF eBook Book Description If you're a web developer looking to leverage the power of AI in your projects, then this book is for you. Written by an AI and ML expert with more than 15 years of experience, AI Strategies for Web Development takes you on a transformative journey through the dynamic intersection of AI and web development, offering a hands-on learning experience.The first part of the book focuses on uncovering the profound impact of AI on web projects, exploring fundamental concepts, and navigating popular frameworks and tools. As you progress, you'll learn how to build smart AI applications with design intelligence, personalized user journeys, and coding assistants. Later, you'll explore how to future-proof your web development projects using advanced AI strategies and understand AI's impact on jobs. Toward the end, you'll immerse yourself in AI-augmented development, crafting intelligent web applications and navigating the ethical landscape.Packed with insights into next-gen development environments, AI-augmented practices, emerging realities, interfaces, and security governance, this web development book acts as your roadmap to staying ahead in the AI and web development domain. What you will learn Build AI-powered web projects with optimized models Personalize UX dynamically with AI, NLP, chatbots, and recommendations Explore AI coding assistants and other tools for advanced web development Craft data-driven, personalized experiences using pattern recognition Architect effective AI solutions while exploring the future of web development Build secure and ethical AI applications following TRiSM best practices Explore cutting-edge AI and web development trends Who this book is for This book is for web developers with experience in programming languages and an interest in keeping up with the latest trends in AI-powered web development. Full-stack, front-end, and back-end developers, UI/UX designers, software engineers, and web development enthusiasts will also find valuable information and practical guidelines for developing smarter websites with AI. To get the most out of this book, it is recommended that you have basic knowledge of programming languages such as HTML, CSS, and JavaScript, as well as a familiarity with machine learning concepts.\r\nRead more at https://play.google.com/store/books/details?id=FzYZEQAAQBAJ&source=gbs_api\r\n\r\n3. \"Artificial Intelligence for Students\" by Vibha Pandey: A multifaceted approach to develop an understanding of AI and its potential applications KEY FEATURES \u25cf AI-informed focuses on AI foundation, applications, and methodologies. \u25cf AI-inquired focuses on computational thinking and bias awareness. \u25cf AI-innovate focuses on creative and critical thinking and the Capstone project. DESCRIPTION AI is a discipline in Computer Science that focuses on developing intelligent machines, machines that can learn and then teach themselves. If you are interested in AI, this book can definitely help you prepare for future careers in AI and related fields. The book is aligned with the CBSE course, which focuses on developing employability and vocational competencies of students in skill subjects. The book is an introduction to the basics of AI. It is divided into three parts \u2013 AI-informed, AI-inquired and AI-innovate. It will help you understand AI's implications on society and the world. You will also develop a deeper understanding of how it works and how it can be used to solve complex real-world problems. Additionally, the book will also focus on important skills such as problem scoping, goal setting, data analysis, and visualization, which are essential for success in AI projects. Lastly, you will learn how decision trees, neural networks, and other AI concepts are commonly used in real-world applications. By the end of the book, you will develop the skills and competencies required to pursue a career in AI. WHAT YOU WILL LEARN \u25cf Get familiar with the basics of AI and Machine Learning. \u25cf Understand how and where AI can be applied. \u25cf Explore different applications of mathematical methods in AI. \u25cf Get tips for improving your skills in Data Storytelling. \u25cf Understand what is AI bias and how it can affect human rights. WHO THIS BOOK IS FOR This book is for CBSE class XI and XII students who want to learn and explore more about AI. Basic knowledge of Statistical concepts, Algebra, and Plotting of equations is a must. TABLE OF CONTENTS 1. Introduction: AI for Everyone 2. AI Applications and Methodologies 3. Mathematics in Artificial Intelligence 4. AI Values (Ethical Decision-Making) 5. Introduction to Storytelling 6. Critical and Creative Thinking 7. Data Analysis 8. Regression 9. Classification and Clustering 10. AI Values (Bias Awareness) 11. Capstone Project 12. Model Lifecycle (Knowledge) 13. Storytelling Through Data 14. AI Applications in Use in Real-World\r\nRead more at https://play.google.com/store/books/details?id=ptq1EAAAQBAJ&source=gbs_api\r\n\r\n4. \"The AI Book\" by Ivana Bartoletti, Anne Leslie and Sh\u00e2n M. Millie: Written by prominent thought leaders in the global fintech space, The AI Book aggregates diverse expertise into a single, informative volume and explains what artifical intelligence really means and how it can be used across financial services today. Key industry developments are explained in detail, and critical insights from cutting-edge practitioners offer first-hand information and lessons learned. Coverage includes: \u00b7 Understanding the AI Portfolio: from machine learning to chatbots, to natural language processing (NLP); a deep dive into the Machine Intelligence Landscape; essentials on core technologies, rethinking enterprise, rethinking industries, rethinking humans; quantum computing and next-generation AI \u00b7 AI experimentation and embedded usage, and the change in business model, value proposition, organisation, customer and co-worker experiences in today\u2019s Financial Services Industry \u00b7 The future state of financial services and capital markets \u2013 what\u2019s next for the real-world implementation of AITech? \u00b7 The innovating customer \u2013 users are not waiting for the financial services industry to work out how AI can re-shape their sector, profitability and competitiveness \u00b7 Boardroom issues created and magnified by AI trends, including conduct, regulation & oversight in an algo-driven world, cybersecurity, diversity & inclusion, data privacy, the \u2018unbundled corporation\u2019 & the future of work, social responsibility, sustainability, and the new leadership imperatives \u00b7 Ethical considerations of deploying Al solutions and why explainable Al is so important\r\nRead more at http://books.google.ca/books?id=oE3YDwAAQBAJ&dq=ai&hl=&source=gbs_api\r\n\r\n5. \"Artificial Intelligence in Society\" by OECD: The artificial intelligence (AI) landscape has evolved significantly from 1950 when Alan Turing first posed the question of whether machines can think. Today, AI is transforming societies and economies. It promises to generate productivity gains, improve well-being and help address global challenges, such as climate change, resource scarcity and health crises.\r\nRead more at https://play.google.com/store/books/details?id=eRmdDwAAQBAJ&source=gbs_api\r\n```\r\n\r\n## Issue \r\n\r\nThis closes #27276 \r\n\r\n## Dependencies\r\n\r\nNo additional dependencies were added\r\n\r\n---------\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 8, "additions": 420, "deletions": 0, "status": "SUCCESS"}, {"committed_date": "2024-11-07T22:48:01Z", "authored_date": "2024-11-07T22:48:01Z", "author": "Massimiliano Pronesti", "message": "cookbook: add Anthropic's contextual retrieval (#27898)\n\nHi there, this PR adds a notebook implementing Anthropic's proposed\r\n[Contextual\r\nretrieval](https://www.anthropic.com/news/contextual-retrieval) to\r\nlangchain's cookbook.", "changed_files_if_available": 2, "additions": 1383, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-07T22:46:56Z", "authored_date": "2024-11-07T22:46:56Z", "author": "Erick Friis", "message": "docs: new stack diagram (#27972)", "changed_files_if_available": 7, "additions": 88, "deletions": 7, "status": "SUCCESS"}, {"committed_date": "2024-11-07T22:23:48Z", "authored_date": "2024-11-07T22:23:48Z", "author": "Erick Friis", "message": "templates,docs: leave templates in v0.2 (#27952)\n\nall template installs will now have to declare `--branch v0.2` to make\r\nclear they aren't compatible with langchain 0.3 (most have a pydantic v1\r\nsetup). e.g.\r\n\r\n```\r\nlangchain-cli app add pirate-speak --branch v0.2\r\n```", "changed_files_if_available": 807, "additions": 12, "deletions": 33552, "status": "SUCCESS"}, {"committed_date": "2024-11-07T21:55:21Z", "authored_date": "2024-11-07T21:55:21Z", "author": "Erick Friis", "message": "docs: ignore case production fork master (#27971)", "changed_files_if_available": 1, "additions": 9, "deletions": 5, "status": "SUCCESS"}, {"committed_date": "2024-11-07T21:47:19Z", "authored_date": "2024-11-07T21:47:19Z", "author": "Shawn Lee", "message": "community: handle chatdeepinfra jsondecode error (#27603)\n\nFixes #27602 \r\n\r\nAdded error handling to return empty dict if args is empty string or\r\nNone.\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 1, "additions": 5, "deletions": 1, "status": "FAILURE"}, {"committed_date": "2024-11-07T21:46:01Z", "authored_date": "2024-11-07T21:46:01Z", "author": "CLOVA Studio \uac1c\ubc1c", "message": "community: fix ClovaXEmbeddings document API link address (#27957)\n\n- **Description:** 404 error occurs because `API reference` link address\r\npath is incorrect on\r\n`langchain/docs/docs/integrations/text_embedding/naver.ipynb`\r\n- **Issue:** fix `API reference` link address correct path.\r\n\r\n@vbarda @efriis", "changed_files_if_available": 1, "additions": 2, "deletions": 2, "status": "SUCCESS"}, {"committed_date": "2024-11-07T20:34:24Z", "authored_date": "2024-11-07T20:34:24Z", "author": "Akshata", "message": "Add ChatModels wrapper for Cloudflare Workers AI (#27645)\n\nThank you for contributing to LangChain!\r\n\r\n- [x] **PR title**: \"community: chat models wrapper for Cloudflare\r\nWorkers AI\"\r\n\r\n\r\n- [x] **PR message**:\r\n- **Description:** Add chat models wrapper for Cloudflare Workers AI.\r\nEnables Langgraph intergration via ChatModel for tool usage, agentic\r\nusage.\r\n\r\n\r\n- [x] **Add tests and docs**: If you're adding a new integration, please\r\ninclude\r\n1. a test for the integration, preferably unit tests that do not rely on\r\nnetwork access,\r\n2. an example notebook showing its use. It lives in\r\n`docs/docs/integrations` directory.\r\n\r\n\r\n- [x] **Lint and test**: Run `make format`, `make lint` and `make test`\r\nfrom the root of the package(s) you've modified. See contribution\r\nguidelines for more: https://python.langchain.com/docs/contributing/\r\n\r\nAdditional guidelines:\r\n- Make sure optional dependencies are imported within a function.\r\n- Please do not add dependencies to pyproject.toml files (even optional\r\nones) unless they are required for unit tests.\r\n- Most PRs should not touch more than one package.\r\n- Changes should be backwards compatible.\r\n- If you are adding something to community, do not re-import it in\r\nlangchain.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of\r\nbaskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.\r\n\r\n---------\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>\r\nCo-authored-by: Chester Curme <chester.curme@gmail.com>", "changed_files_if_available": 4, "additions": 588, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-07T18:19:22Z", "authored_date": "2024-11-07T18:19:22Z", "author": "Erick Friis", "message": "box: migrate to repo (#27969)", "changed_files_if_available": 34, "additions": 4, "deletions": 3449, "status": "SUCCESS"}, {"committed_date": "2024-11-07T16:48:45Z", "authored_date": "2024-11-07T16:48:45Z", "author": "ccurme", "message": "docs[patch]: update cassettes for sql/csv notebook (#27966)", "changed_files_if_available": 9, "additions": 9, "deletions": 9, "status": "SUCCESS"}, {"committed_date": "2024-11-07T16:16:29Z", "authored_date": "2024-11-07T16:16:29Z", "author": "ccurme", "message": "anthropic[patch]: remove retired model from tests (#27965)\n\n`claude-instant` was [retired\r\nyesterday](https://docs.anthropic.com/en/docs/resources/model-deprecations).", "changed_files_if_available": 1, "additions": 2, "deletions": 2, "status": "SUCCESS"}, {"committed_date": "2024-11-07T03:40:21Z", "authored_date": "2024-11-07T03:40:21Z", "author": "Aksel Joonas Reedi", "message": "community: bytes as a source to `AzureAIDocumentIntelligenceLoader` (#26618)\n\n- **Description:** This PR adds functionality to pass in in-memory bytes\r\nas a source to `AzureAIDocumentIntelligenceLoader`.\r\n- **Issue:** I needed the functionality, so I added it.\r\n- **Dependencies:** NA\r\n- **Twitter handle:** @akseljoonas if this is a big enough change :)\r\n\r\n---------\r\n\r\nCo-authored-by: Aksel Joonas Reedi <aksel@klippa.com>\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 2, "additions": 33, "deletions": 6, "status": "SUCCESS"}, {"committed_date": "2024-11-07T03:14:57Z", "authored_date": "2024-11-07T03:14:57Z", "author": "Martin Triska", "message": "community: ZeroxPDFLoader (#27800)\n\n# OCR-based PDF loader\r\n\r\nThis implements [Zerox](https://github.com/getomni-ai/zerox) PDF\r\ndocument loader.\r\nZerox utilizes simple but very powerful (even though slower and more\r\ncostly) approach to parsing PDF documents: it converts PDF to series of\r\nimages and passes it to a vision model requesting the contents in\r\nmarkdown.\r\n\r\nIt is especially suitable for complex PDFs that are not parsed well by\r\nother alternatives.\r\n\r\n## Example use:\r\n```python\r\nfrom langchain_community.document_loaders.pdf import ZeroxPDFLoader\r\n\r\nos.environ[\"OPENAI_API_KEY\"] = \"\" ## your-api-key\r\n\r\nmodel = \"gpt-4o-mini\" ## openai model\r\npdf_url = \"https://assets.ctfassets.net/f1df9zr7wr1a/soP1fjvG1Wu66HJhu3FBS/034d6ca48edb119ae77dec5ce01a8612/OpenAI_Sacra_Teardown.pdf\"\r\n\r\nloader = ZeroxPDFLoader(file_path=pdf_url, model=model)\r\ndocs = loader.load()\r\n```\r\n\r\nThe Zerox library supports wide range of provides/models. See Zerox\r\ndocumentation for details.\r\n\r\n- **Dependencies:** `zerox`\r\n- **Twitter handle:** @martintriska1\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of\r\nbaskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.\r\n\r\n---------\r\n\r\nCo-authored-by: Erick Friis <erickfriis@gmail.com>", "changed_files_if_available": 2, "additions": 354, "deletions": 0, "status": "SUCCESS"}, {"committed_date": "2024-11-07T03:07:59Z", "authored_date": "2024-11-07T03:07:59Z", "author": "Dmitriy Prokopchuk", "message": "community: Memcached LLM Cache Integration (#27323)\n\n## Description\r\nThis PR adds support for Memcached as a usable LLM model cache by adding\r\nthe ```MemcachedCache``` implementation relying on the\r\n[pymemcache](https://github.com/pinterest/pymemcache) client.\r\n\r\nUnit test-wise, the new integration is generally covered under existing\r\nimport testing. All new functionality depends on pymemcache if\r\ninstantiated and used, so to comply with the other cache implementations\r\nthe PR also adds optional integration tests for ```MemcachedCache```.\r\n\r\nSince this is a new integration, documentation is added for Memcached as\r\nan integration and as an LLM Cache.\r\n\r\n## Issue\r\nThis PR closes #27275 which was originally raised as a discussion in\r\n#27035\r\n\r\n## Dependencies\r\nThere are no new required dependencies for langchain, but\r\n[pymemcache](https://github.com/pinterest/pymemcache) is required to\r\ninstantiate the new ```MemcachedCache```.\r\n\r\n## Example Usage\r\n```python3\r\nfrom langchain.globals import set_llm_cache\r\nfrom langchain_openai import OpenAI\r\n\r\nfrom langchain_community.cache import MemcachedCache\r\nfrom pymemcache.client.base import Client\r\n\r\nllm = OpenAI(model=\"gpt-3.5-turbo-instruct\", n=2, best_of=2)\r\nset_llm_cache(MemcachedCache(Client('localhost')))\r\n\r\n# The first time, it is not yet in cache, so it should take longer\r\nllm.invoke(\"Which city is the most crowded city in the USA?\")\r\n\r\n# The second time it is, so it goes faster\r\nllm.invoke(\"Which city is the most crowded city in the USA?\")\r\n```\r\n\r\n---------\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 4, "additions": 285, "deletions": 0, "status": "SUCCESS"}, {"committed_date": "2024-11-07T02:47:41Z", "authored_date": "2024-11-07T02:47:41Z", "author": "Siddharth Murching", "message": "community: Update UC toolkit documentation to use LangGraph APIs (#26778)\n\n- **Description:** Update UC toolkit documentation to show an example of\r\nusing recommended LangGraph agent APIs before the existing LangChain\r\nAgentExecutor example. Tested by manually running the updated example\r\nnotebook\r\n- **Dependencies:** No new dependencies\r\n\r\n---------\r\n\r\nSigned-off-by: Sid Murching <sid.murching@databricks.com>\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 1, "additions": 91, "deletions": 21, "status": "SUCCESS"}, {"committed_date": "2024-11-07T02:42:41Z", "authored_date": "2024-11-07T02:42:41Z", "author": "ZhangShenao", "message": "Improvement[Partner] Improve qdrant vector store (#27251)\n\n- Add static method decorator\r\n- Add args for api doc\r\n- Fix word spelling\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 2, "additions": 5, "deletions": 5, "status": "SUCCESS"}, {"committed_date": "2024-11-07T01:26:30Z", "authored_date": "2024-11-07T01:26:30Z", "author": "Baptiste Pasquier", "message": "community: add InfinityRerank (#27043)\n\n**Description:** \r\n\r\n- Add a Reranker for Infinity server.\r\n\r\n**Dependencies:** \r\n\r\nThis wrapper uses\r\n[infinity_client](https://github.com/michaelfeil/infinity/tree/main/libs/client_infinity/infinity_client)\r\nto connect to an Infinity server.\r\n\r\n**Tests and docs**\r\n\r\n- integration test: test_infinity_rerank.py\r\n- example notebook: infinity_rerank.ipynb\r\n[here](https://github.com/baptiste-pasquier/langchain/blob/feat/infinity-rerank/docs/docs/integrations/document_transformers/infinity_rerank.ipynb)\r\n\r\n---------\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 5, "additions": 578, "deletions": 0, "status": "SUCCESS"}, {"committed_date": "2024-11-07T00:31:10Z", "authored_date": "2024-11-07T00:31:10Z", "author": "Erick Friis", "message": "infra: remove google creds from release and integration test workflows (#27950)", "changed_files_if_available": 2, "additions": 0, "deletions": 12, "status": "SUCCESS"}, {"committed_date": "2024-11-06T22:44:34Z", "authored_date": "2024-11-06T22:44:34Z", "author": "Martin Triska", "message": "community: Allow other than default parsers in SharePointLoader and OneDriveLoader (#27716)\n\n## What this PR does?\r\n\r\n### Currently `O365BaseLoader` (and consequently both derived loaders)\r\nare limited to `pdf`, `doc`, `docx` files.\r\n- **Solution: here we introduce _handlers_ attribute that allows for\r\ncustom handlers to be passed in. This is done in _dict_ form:**\r\n\r\n**Example:**\r\n```python\r\nfrom langchain_community.document_loaders.parsers.documentloader_adapter import DocumentLoaderAsParser\r\n# PR for DocumentLoaderAsParser here: https://github.com/langchain-ai/langchain/pull/27749\r\nfrom langchain_community.document_loaders.excel import UnstructuredExcelLoader\r\n\r\nxlsx_parser = DocumentLoaderAsParser(UnstructuredExcelLoader, mode=\"paged\")\r\n\r\n# create dictionary mapping file types to handlers (parsers)\r\nhandlers = {\r\n    \"doc\": MsWordParser()\r\n    \"pdf\": PDFMinerParser()\r\n    \"txt\": TextParser()\r\n    \"xlsx\": xlsx_parser\r\n}\r\nloader = SharePointLoader(document_library_id=\"...\",\r\n                            handlers=handlers # pass handlers to SharePointLoader\r\n                            )\r\ndocuments = loader.load()\r\n\r\n# works the same in OneDriveLoader\r\nloader = OneDriveLoader(document_library_id=\"...\",\r\n                            handlers=handlers\r\n                            )\r\n```\r\nThis dictionary is then passed to `MimeTypeBasedParser` same as in the\r\n[current\r\nimplementation](https://github.com/langchain-ai/langchain/blob/5a2cfb49e045988d290a1c7e3a0c589d6b371694/libs/community/langchain_community/document_loaders/parsers/registry.py#L13).\r\n\r\n\r\n### Currently `SharePointLoader` and `OneDriveLoader` are separate\r\nloaders that both inherit from `O365BaseLoader`\r\nHowever both of these implement the same functionality. The only\r\ndifferences are:\r\n- `SharePointLoader` requires argument `document_library_id` whereas\r\n`OneDriveLoader` requires `drive_id`. These are just different names for\r\nthe same thing.\r\n  - `SharePointLoader` implements significantly more features.\r\n- **Solution: `OneDriveLoader` is replaced with an empty shell just\r\nrenaming `drive_id` to `document_library_id` and inheriting from\r\n`SharePointLoader`**\r\n\r\n**Dependencies:** None\r\n**Twitter handle:** @martintriska1\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of\r\nbaskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.", "changed_files_if_available": 5, "additions": 227, "deletions": 136, "status": "FAILURE"}, {"committed_date": "2024-11-06T22:37:07Z", "authored_date": "2024-11-06T22:37:07Z", "author": "takahashi", "message": "langchain_core: add `file_type` option to make file type default as `png` (#27855)\n\nThank you for contributing to LangChain!\r\n\r\n- [ ] **PR title**: \"package: description\"\r\n- Where \"package\" is whichever of langchain, community, core, etc. is\r\nbeing modified. Use \"docs: ...\" for purely docs changes, \"templates:\r\n...\" for template changes, \"infra: ...\" for CI changes.\r\n  - Example: \"community: add foobar LLM\"\r\n\r\n- [ ] **description**\r\nlangchain_core.runnables.graph_mermaid.draw_mermaid_png calls this\r\nfunction, but the Mermaid API returns JPEG by default. To be consistent,\r\nadd the option `file_type` with the default `png` type.\r\n\r\n- [ ] **Add tests and docs**: If you're adding a new integration, please\r\ninclude\r\nWith this small change, I didn't add tests and docs.\r\n\r\n- [ ] **Lint and test**: Run `make format`, `make lint` and `make test`\r\nfrom the root of the package(s) you've modified. See contribution\r\nguidelines for more:\r\nOne long sentence was divided into two.\r\n\r\nAdditional guidelines:\r\n- Make sure optional dependencies are imported within a function.\r\n- Please do not add dependencies to pyproject.toml files (even optional\r\nones) unless they are required for unit tests.\r\n- Most PRs should not touch more than one package.\r\n- Changes should be backwards compatible.\r\n- If you are adding something to community, do not re-import it in\r\nlangchain.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of\r\nbaskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.", "changed_files_if_available": 1, "additions": 4, "deletions": 2, "status": "SUCCESS"}, {"committed_date": "2024-11-06T22:35:39Z", "authored_date": "2024-11-06T22:35:39Z", "author": "Roman Solomatin", "message": "langchain-huggingface: use separate kwargs for queries and docs (#27857)\n\nNow `encode_kwargs` used for both for documents and queries and this\r\nleads to wrong embeddings. E. g.:\r\n```python\r\n    model_kwargs = {\"device\": \"cuda\", \"trust_remote_code\": True}\r\n    encode_kwargs = {\"normalize_embeddings\": False, \"prompt_name\": \"s2p_query\"}\r\n\r\n    model = HuggingFaceEmbeddings(\r\n        model_name=\"dunzhang/stella_en_400M_v5\",\r\n        model_kwargs=model_kwargs,\r\n        encode_kwargs=encode_kwargs,\r\n    )\r\n\r\n    query_embedding = np.array(\r\n        model.embed_query(\"What are some ways to reduce stress?\",)\r\n    )\r\n    document_embedding = np.array(\r\n        model.embed_documents(\r\n            [\r\n                \"There are many effective ways to reduce stress. Some common techniques include deep breathing, meditation, and physical activity. Engaging in hobbies, spending time in nature, and connecting with loved ones can also help alleviate stress. Additionally, setting boundaries, practicing self-care, and learning to say no can prevent stress from building up.\",\r\n                \"Green tea has been consumed for centuries and is known for its potential health benefits. It contains antioxidants that may help protect the body against damage caused by free radicals. Regular consumption of green tea has been associated with improved heart health, enhanced cognitive function, and a reduced risk of certain types of cancer. The polyphenols in green tea may also have anti-inflammatory and weight loss properties.\",\r\n            ]\r\n        )\r\n    )\r\n    print(model._client.similarity(query_embedding, document_embedding)) # output: tensor([[0.8421, 0.3317]], dtype=torch.float64)\r\n```\r\nBut from the [model\r\ncard](https://huggingface.co/dunzhang/stella_en_400M_v5#sentence-transformers)\r\nexpexted like this:\r\n```python\r\n    model_kwargs = {\"device\": \"cuda\", \"trust_remote_code\": True}\r\n    encode_kwargs = {\"normalize_embeddings\": False}\r\n    query_encode_kwargs = {\"normalize_embeddings\": False, \"prompt_name\": \"s2p_query\"}\r\n\r\n    model = HuggingFaceEmbeddings(\r\n        model_name=\"dunzhang/stella_en_400M_v5\",\r\n        model_kwargs=model_kwargs,\r\n        encode_kwargs=encode_kwargs,\r\n        query_encode_kwargs=query_encode_kwargs,\r\n    )\r\n\r\n    query_embedding = np.array(\r\n        model.embed_query(\"What are some ways to reduce stress?\", )\r\n    )\r\n    document_embedding = np.array(\r\n        model.embed_documents(\r\n            [\r\n                \"There are many effective ways to reduce stress. Some common techniques include deep breathing, meditation, and physical activity. Engaging in hobbies, spending time in nature, and connecting with loved ones can also help alleviate stress. Additionally, setting boundaries, practicing self-care, and learning to say no can prevent stress from building up.\",\r\n                \"Green tea has been consumed for centuries and is known for its potential health benefits. It contains antioxidants that may help protect the body against damage caused by free radicals. Regular consumption of green tea has been associated with improved heart health, enhanced cognitive function, and a reduced risk of certain types of cancer. The polyphenols in green tea may also have anti-inflammatory and weight loss properties.\",\r\n            ]\r\n        )\r\n    )\r\n    print(model._client.similarity(query_embedding, document_embedding)) # tensor([[0.8398, 0.2990]], dtype=torch.float64)\r\n```", "changed_files_if_available": 1, "additions": 34, "deletions": 7, "status": "SUCCESS"}, {"committed_date": "2024-11-06T22:25:13Z", "authored_date": "2024-11-06T22:25:13Z", "author": "Bagatur", "message": "docs: fix trim_messages docstring (#27948)", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-06T21:28:27Z", "authored_date": "2024-11-06T21:28:27Z", "author": "murrlincoln", "message": "docs: Adding notebook for cdp agentkit toolkit (#27910)\n\n- **Description:** Adding in the first pass of documentation for the CDP\r\nAgentkit Toolkit\r\n    - **Issue:** N/a\r\n    - **Dependencies:** cdp-langchain\r\n    - **Twitter handle:** @CoinbaseDev\r\n\r\n---------\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>\r\nCo-authored-by: John Peterson <john.peterson@coinbase.com>", "changed_files_if_available": 1, "additions": 332, "deletions": 0, "status": "SUCCESS"}, {"committed_date": "2024-11-06T20:04:09Z", "authored_date": "2024-11-06T20:04:09Z", "author": "Eric Pinzur", "message": "community: added Document.id support to opensearch vectorstore (#27945)\n\nDescription:\r\n* Added support of Document.id on OpenSearch vector store\r\n* Added tests cases to match", "changed_files_if_available": 2, "additions": 55, "deletions": 21, "status": "SUCCESS"}, {"committed_date": "2024-11-06T19:55:00Z", "authored_date": "2024-11-06T19:55:00Z", "author": "Hammad Randhawa", "message": "docs: Completed sentence under the heading  \"Instantiating a Browser \u2026 (#27944)\n\n\u2026Toolkit\" in \"playwright.ipynb\" integration.\r\n\r\n- Completed the incomplete sentence in the Langchain Playwright\r\ndocumentation.\r\n\r\n- Enhanced documentation clarity to guide users on best practices for\r\ninstantiating browser instances with Langchain Playwright.\r\n\r\nExample before:\r\n> \"It's always recommended to instantiate using the from_browser method\r\nso that the\r\n\r\nExample after:\r\n> \"It's always recommended to instantiate using the `from_browser`\r\nmethod so that the browser context is properly initialized and managed,\r\nensuring seamless interaction and resource optimization.\"\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-06T18:06:47Z", "authored_date": "2024-11-06T18:06:47Z", "author": "Bagatur", "message": "core[patch]: make oai tool description optional (#27756)", "changed_files_if_available": 2, "additions": 174, "deletions": 23, "status": "SUCCESS"}, {"committed_date": "2024-11-06T17:50:07Z", "authored_date": "2024-11-06T17:50:07Z", "author": "Bagatur", "message": "docs: document init_chat_model standard params (#27812)", "changed_files_if_available": 1, "additions": 10, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-06T14:58:16Z", "authored_date": "2024-11-06T14:58:16Z", "author": "Dobiichi-Origami", "message": "community: re-arrange function call message parse logic for Qianfan (#27935)\n\nthe [PR](https://github.com/langchain-ai/langchain/pull/26208) two month\r\nago has a potential bug which causes malfunction of `tool_call` for\r\n`QianfanChatEndpoint` waiting for fix", "changed_files_if_available": 1, "additions": 3, "deletions": 7, "status": "SUCCESS"}, {"committed_date": "2024-11-06T00:43:11Z", "authored_date": "2024-11-06T00:43:11Z", "author": "Erick Friis", "message": "infra: starter codeowners file (#27929)", "changed_files_if_available": 1, "additions": 2, "deletions": 0, "status": "SUCCESS"}, {"committed_date": "2024-11-05T23:02:24Z", "authored_date": "2024-11-05T23:02:24Z", "author": "ccurme", "message": "openai[patch]: release 0.2.6 (#27924)\n\nSome additions in support of [predicted\r\noutputs](https://platform.openai.com/docs/guides/latency-optimization#use-predicted-outputs)\r\nfeature:\r\n- Bump openai sdk version\r\n- Add integration test\r\n- Add example to integration docs\r\n\r\nThe `prediction` kwarg is already plumbed through model invocation.", "changed_files_if_available": 4, "additions": 150, "deletions": 12, "status": "SUCCESS"}, {"committed_date": "2024-11-05T20:55:38Z", "authored_date": "2024-11-05T20:55:38Z", "author": "Erick Friis", "message": "standard-tests: ci pipeline (#27923)", "changed_files_if_available": 5, "additions": 71, "deletions": 7, "status": "SUCCESS"}, {"committed_date": "2024-11-05T20:44:36Z", "authored_date": "2024-11-05T20:44:36Z", "author": "Erick Friis", "message": "infra: release note grep order of operations (#27922)", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-05T20:04:41Z", "authored_date": "2024-11-05T20:04:41Z", "author": "Erick Friis", "message": "infra: release note compute 2 (#27921)", "changed_files_if_available": 1, "additions": 10, "deletions": 5, "status": "SUCCESS"}, {"committed_date": "2024-11-05T19:44:34Z", "authored_date": "2024-11-05T19:44:34Z", "author": "Erick Friis", "message": "standard-tests: add tools standard tests (#27899)", "changed_files_if_available": 2, "additions": 144, "deletions": 0, "status": "SUCCESS"}, {"committed_date": "2024-11-05T19:43:11Z", "authored_date": "2024-11-05T19:43:11Z", "author": "SHJUN", "message": "community: chroma error patch(attribute changed on chroma) (#27827)\n\nThere was a change of attribute name which was \"max_batch_size\". It's\r\nnow \"get_max_batch_size\" method.\r\nI want to use \"create_batches\" which is right down below.\r\n\r\nPlease check this PR link.\r\nreference: https://github.com/chroma-core/chroma/pull/2305\r\n\r\n---------\r\n\r\nSigned-off-by: Prithvi Kannan <prithvi.kannan@databricks.com>\r\nCo-authored-by: Prithvi Kannan <46332835+prithvikannan@users.noreply.github.com>\r\nCo-authored-by: Bagatur <22008038+baskaryan@users.noreply.github.com>\r\nCo-authored-by: Erick Friis <erick@langchain.dev>\r\nCo-authored-by: Jun Yamog <jkyamog@gmail.com>\r\nCo-authored-by: Bagatur <baskaryan@gmail.com>\r\nCo-authored-by: ono-hiroki <86904208+ono-hiroki@users.noreply.github.com>\r\nCo-authored-by: Dobiichi-Origami <56953648+Dobiichi-Origami@users.noreply.github.com>\r\nCo-authored-by: Chester Curme <chester.curme@gmail.com>\r\nCo-authored-by: Duy Huynh <vndee.huynh@gmail.com>\r\nCo-authored-by: Rashmi Pawar <168514198+raspawar@users.noreply.github.com>\r\nCo-authored-by: sifatj <26035630+sifatj@users.noreply.github.com>\r\nCo-authored-by: Eric Pinzur <2641606+epinzur@users.noreply.github.com>\r\nCo-authored-by: Daniel Vu Dao <danielvdao@users.noreply.github.com>\r\nCo-authored-by: Ofer Mendelevitch <ofermend@gmail.com>\r\nCo-authored-by: St\u00e9phane Philippart <wildagsx@gmail.com>", "changed_files_if_available": 2, "additions": 11, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-05T16:54:26Z", "authored_date": "2024-11-05T16:54:26Z", "author": "Tomaz Bratanic", "message": "update llm graph transformer documentation (#27905)", "changed_files_if_available": 3, "additions": 110, "deletions": 10, "status": "SUCCESS"}, {"committed_date": "2024-11-05T01:29:15Z", "authored_date": "2024-11-05T01:29:15Z", "author": "Erick Friis", "message": "standard-tests: release 0.3.0 (#27900)", "changed_files_if_available": 2, "additions": 282, "deletions": 266, "status": "SUCCESS"}, {"committed_date": "2024-11-04T23:46:13Z", "authored_date": "2024-11-04T23:46:13Z", "author": "Erick Friis", "message": "infra: get min versions (#27896)", "changed_files_if_available": 4, "additions": 76, "deletions": 25, "status": "SUCCESS"}, {"committed_date": "2024-11-04T22:09:32Z", "authored_date": "2024-11-04T22:09:32Z", "author": "Bagatur", "message": "docs: sidebar capitalization (#27894)", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-04T21:40:30Z", "authored_date": "2024-11-04T21:40:30Z", "author": "St\u00e9phane Philippart", "message": "community: \u2728 Use new OVHcloud batch embedding (#26209)\n\n- **Description:** change to do the batch embedding server side and not\r\nclient side\r\n- **Twitter handle:** @wildagsx\r\n\r\n---------\r\n\r\nCo-authored-by: ccurme <chester.curme@gmail.com>", "changed_files_if_available": 1, "additions": 42, "deletions": 22, "status": "SUCCESS"}, {"committed_date": "2024-11-04T20:46:23Z", "authored_date": "2024-11-04T20:46:23Z", "author": "Erick Friis", "message": "infra: fix prev tag output (#27892)", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-04T20:42:22Z", "authored_date": "2024-11-04T20:42:22Z", "author": "Erick Friis", "message": "infra: fix prev tag condition (#27891)", "changed_files_if_available": 1, "additions": 2, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-04T20:40:39Z", "authored_date": "2024-11-04T20:40:39Z", "author": "Ofer Mendelevitch", "message": "community: update Vectara integration (#27869)\n\nThank you for contributing to LangChain!\r\n\r\n- **Description:** Updated Vectara integration\r\n- **Issue:** refresh on descriptions across all demos and added UDF\r\nreranker\r\n- **Dependencies:** None\r\n- **Twitter handle:** @ofermend\r\n\r\n---------\r\n\r\nCo-authored-by: Bagatur <baskaryan@gmail.com>\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 6, "additions": 60, "deletions": 25, "status": "FAILURE"}, {"committed_date": "2024-11-04T20:38:39Z", "authored_date": "2024-11-04T20:38:39Z", "author": "Erick Friis", "message": "infra: fix prev tag calculation (#27890)", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "FAILURE"}, {"committed_date": "2024-11-04T20:36:31Z", "authored_date": "2024-11-04T20:36:31Z", "author": "Daniel Vu Dao", "message": "docs: Update `messages.mdx` (#27856)\n\n### Description\r\nUpdates phrasing for the header of the `Messages` section.\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "FAILURE"}, {"committed_date": "2024-11-04T20:34:50Z", "authored_date": "2024-11-04T20:34:50Z", "author": "sifatj", "message": "docs: Update VectorStore as_retriever method url in qa_chat_history_how_to.ipynb (#27844)\n\n**Description**: Update VectorStore `as_retriever` method api reference\r\nurl in `qa_chat_history_how_to.ipynb`\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "FAILURE"}, {"committed_date": "2024-11-04T20:31:36Z", "authored_date": "2024-11-04T20:31:36Z", "author": "sifatj", "message": "docs: Update max_marginal_relevance_search api reference url in multi_vector.ipynb (#27843)\n\n**Description**: Update VectorStore `max_marginal_relevance_search` api\r\nreference url in `multi_vector.ipynb`\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-04T20:28:11Z", "authored_date": "2024-11-04T20:28:11Z", "author": "sifatj", "message": "docs: Update VectorStore .as_retriever method url in vectorstore_retriever.ipynb (#27842)\n\n**Description**: Update VectorStore `.as_retriever` method url in\r\n`vectorstore_retriever.ipynb`\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "FAILURE"}, {"committed_date": "2024-11-04T20:27:17Z", "authored_date": "2024-11-04T20:27:17Z", "author": "Eric Pinzur", "message": "community: fixed bug in GraphVectorStoreRetriever (#27846)\n\nDescription:\r\n\r\nThis fixes an issue that mistakenly created in\r\nhttps://github.com/langchain-ai/langchain/pull/27253. The issue\r\ncurrently exists only in `langchain-community==0.3.4`.\r\n\r\nTest cases were added to prevent this issue in the future.\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 2, "additions": 36, "deletions": 7, "status": "FAILURE"}, {"committed_date": "2024-11-04T20:27:03Z", "authored_date": "2024-11-04T20:27:03Z", "author": "sifatj", "message": "docs: Update VectorStore api reference url in rag.ipynb (#27841)\n\n**Description**: Update VectorStore api reference url in `rag.ipynb`\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "FAILURE"}, {"committed_date": "2024-11-04T20:26:03Z", "authored_date": "2024-11-04T20:26:03Z", "author": "sifatj", "message": "docs: Update broken vectorstore urls in retrievers.ipynb (#27838)\n\n**Description**: Update outdated `VectorStore` api reference urls in\r\n`retrievers.ipynb`\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 1, "additions": 5, "deletions": 5, "status": "FAILURE"}, {"committed_date": "2024-11-04T20:19:50Z", "authored_date": "2024-11-04T20:19:50Z", "author": "Bagatur", "message": "qdrant,nomic[minor]: bump core deps (#27849)", "changed_files_if_available": 5, "additions": 1342, "deletions": 1240, "status": "SUCCESS"}, {"committed_date": "2024-11-04T20:16:51Z", "authored_date": "2024-11-04T20:16:51Z", "author": "Erick Friis", "message": "infra: release tag compute (#27836)", "changed_files_if_available": 1, "additions": 19, "deletions": 4, "status": "SUCCESS"}, {"committed_date": "2024-11-04T19:45:51Z", "authored_date": "2024-11-04T19:45:51Z", "author": "Rashmi Pawar", "message": "Add nvidia as provider for embedding, llm (#27810)\n\nDocumentation: Add NVIDIA as integration provider\r\n\r\ncc: @mattf @dglogo\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>", "changed_files_if_available": 1, "additions": 12, "deletions": 0, "status": "SUCCESS"}, {"committed_date": "2024-11-04T18:18:38Z", "authored_date": "2024-11-04T18:18:38Z", "author": "Erick Friis", "message": "Revert \"infra: add neo4j to package list\" (#27887)\n\nReverts langchain-ai/langchain#27833\r\n\r\nWait for release", "changed_files_if_available": 1, "additions": 0, "deletions": 4, "status": "SUCCESS"}, {"committed_date": "2024-11-04T17:24:04Z", "authored_date": "2024-11-04T17:24:04Z", "author": "Erick Friis", "message": "infra: add neo4j to package list (#27833)", "changed_files_if_available": 1, "additions": 4, "deletions": 0, "status": "SUCCESS"}, {"committed_date": "2024-11-04T14:34:27Z", "authored_date": "2024-11-04T14:34:27Z", "author": "Duy Huynh", "message": "community: set default `output_token_limit` value for `PowerBIToolkit` to fix validation error (#26308)\n\n### Description:\r\nThis PR sets a default value of `output_token_limit = 4000` for the\r\n`PowerBIToolkit` to fix the unintentionally validation error.\r\n\r\n### Problem:\r\nWhen attempting to run a code snippet from [Langchain's PowerBI toolkit\r\ndocumentation](https://python.langchain.com/v0.1/docs/integrations/toolkits/powerbi/)\r\nto interact with a `PowerBIDataset`, the following error occurs:\r\n\r\n```\r\npydantic.v1.error_wrappers.ValidationError: 1 validation error for QueryPowerBITool\r\noutput_token_limit\r\n  none is not an allowed value (type=type_error.none.not_allowed)\r\n```\r\n\r\n### Root Cause:\r\nThe issue arises because when creating a `QueryPowerBITool`, the\r\n`output_token_limit` parameter is unintentionally set to `None`, which\r\nis the current default for `PowerBIToolkit`. However, `QueryPowerBITool`\r\nexpects a default value of `4000` for `output_token_limit`. This\r\nunintended override causes the error.\r\n\r\n\r\nhttps://github.com/langchain-ai/langchain/blob/17659ca2cdc418436edf2f8c7f50e800dbbf31ca/libs/community/langchain_community/agent_toolkits/powerbi/toolkit.py#L63\r\n\r\nhttps://github.com/langchain-ai/langchain/blob/17659ca2cdc418436edf2f8c7f50e800dbbf31ca/libs/community/langchain_community/agent_toolkits/powerbi/toolkit.py#L72-L79\r\n\r\nhttps://github.com/langchain-ai/langchain/blob/17659ca2cdc418436edf2f8c7f50e800dbbf31ca/libs/community/langchain_community/tools/powerbi/tool.py#L39\r\n\r\n### Solution:\r\nTo resolve this, the default value of `output_token_limit` is now\r\nexplicitly set to `4000` in `PowerBIToolkit` to prevent the accidental\r\nassignment of `None`.\r\n\r\nCo-authored-by: ccurme <chester.curme@gmail.com>", "changed_files_if_available": 1, "additions": 2, "deletions": 2, "status": "SUCCESS"}, {"committed_date": "2024-11-04T14:33:32Z", "authored_date": "2024-11-04T14:33:32Z", "author": "Dobiichi-Origami", "message": "community: read function call from `tool_calls` for Qianfan (#26208)\n\nI added one more 'elif' to read tool call message from `tool_calls`\r\n\r\n---------\r\n\r\nCo-authored-by: Chester Curme <chester.curme@gmail.com>", "changed_files_if_available": 1, "additions": 10, "deletions": 3, "status": "SUCCESS"}, {"committed_date": "2024-11-04T14:10:56Z", "authored_date": "2024-11-04T14:10:56Z", "author": "ono-hiroki", "message": "docs: fix undefined 'data' variable in document_loader_csv.ipynb (#27872)\n\n**Description:** \r\nThis PR addresses an issue in the CSVLoader example where data is not\r\ndefined, causing a NameError. The line `data = loader.load()` is added\r\nto correctly assign the output of loader.load() to the data variable.", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-02T01:12:00Z", "authored_date": "2024-11-02T01:12:00Z", "author": "Bagatur", "message": "chroma[minor]: release 0.2.0 (#27840)", "changed_files_if_available": 2, "additions": 363, "deletions": 398, "status": "SUCCESS"}, {"committed_date": "2024-11-01T22:42:24Z", "authored_date": "2024-11-01T22:42:24Z", "author": "Jun Yamog", "message": "core: fix CommaSeparatedListOutputParser to handle columns that may contain commas in it (#26365)\n\n- **Description:**\r\nCurrently CommaSeparatedListOutputParser can't handle strings that may\r\ncontain commas within a column. It would parse any commas as the\r\ndelimiter.\r\nEx. \r\n\"foo, foo2\", \"bar\", \"baz\"\r\n\r\nIt will create 4 columns: \"foo\", \"foo2\", \"bar\", \"baz\"\r\n\r\nThis should be 3 columns:\r\n\r\n\"foo, foo2\", \"bar\", \"baz\"\r\n\r\n- **Dependencies:**\r\nAdded 2 additional imports, but they are built in python packages.\r\n\r\nimport csv\r\nfrom io import StringIO\r\n\r\n- **Twitter handle:** @jkyamog\r\n\r\n- [ ] **Add tests and docs**: \r\n1. added simple unit test test_multiple_items_with_comma\r\n\r\n---------\r\n\r\nCo-authored-by: Erick Friis <erick@langchain.dev>\r\nCo-authored-by: Bagatur <22008038+baskaryan@users.noreply.github.com>\r\nCo-authored-by: Bagatur <baskaryan@gmail.com>", "changed_files_if_available": 2, "additions": 29, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-01T21:35:11Z", "authored_date": "2024-11-01T21:35:11Z", "author": "Erick Friis", "message": "docs: INVALID_CHAT_HISTORY redirect (#27845)", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-01T21:13:43Z", "authored_date": "2024-11-01T21:13:43Z", "author": "Erick Friis", "message": "infra: remove some special cases (#27839)", "changed_files_if_available": 6, "additions": 1, "deletions": 11, "status": "SUCCESS"}, {"committed_date": "2024-11-01T20:59:34Z", "authored_date": "2024-11-01T20:59:34Z", "author": "Bagatur", "message": "airbyte: remove from master (#27837)", "changed_files_if_available": 18, "additions": 0, "deletions": 3422, "status": "SUCCESS"}, {"committed_date": "2024-11-01T20:35:55Z", "authored_date": "2024-11-01T20:35:55Z", "author": "Bagatur", "message": "many: use core 0.3.15 (#27834)", "changed_files_if_available": 22, "additions": 545, "deletions": 443, "status": "SUCCESS"}, {"committed_date": "2024-11-01T17:21:19Z", "authored_date": "2024-11-01T17:21:19Z", "author": "Prithvi Kannan", "message": "docs: Reference new databricks-langchain package (#27828)\n\nThank you for contributing to LangChain!\r\n\r\nUpdate references in Databricks integration page to reference our new\r\npartner package databricks-langchain\r\nhttps://github.com/databricks/databricks-ai-bridge/tree/main/integrations/langchain\r\n\r\nAdditional guidelines:\r\n- Make sure optional dependencies are imported within a function.\r\n- Please do not add dependencies to pyproject.toml files (even optional\r\nones) unless they are required for unit tests.\r\n- Most PRs should not touch more than one package.\r\n- Changes should be backwards compatible.\r\n- If you are adding something to community, do not re-import it in\r\nlangchain.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of\r\nbaskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.\r\n\r\n---------\r\n\r\nSigned-off-by: Prithvi Kannan <prithvi.kannan@databricks.com>", "changed_files_if_available": 1, "additions": 6, "deletions": 16, "status": "SUCCESS"}, {"committed_date": "2024-11-01T15:44:26Z", "authored_date": "2024-11-01T15:44:26Z", "author": "sifatj", "message": "docs: update VectorStore api reference url in retrievers.ipynb (#27814)\n\n**Description:** Update outdated `VectorStore` api reference url in\r\nVector store subsection of `retrievers.ipynb`", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-11-01T15:42:30Z", "authored_date": "2024-11-01T15:42:30Z", "author": "sifatj", "message": "docs: Update Retrievers and Runnable links in Retrievers subsection of retrievers.ipynb (#27815)\n\n**Description:** Update outdated links for `Retrievers` and `Runnable`\r\nin Retrievers subsection of `retrievers.ipynb`", "changed_files_if_available": 1, "additions": 2, "deletions": 2, "status": "SUCCESS"}, {"committed_date": "2024-11-01T15:32:07Z", "authored_date": "2024-11-01T15:32:07Z", "author": "Zapiron", "message": "Fixed broken link for TokenTextSplitter (#27824)\n\nFixed the broken redirect link for `TokenTextSplitter` section", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-10-31T22:29:34Z", "authored_date": "2024-10-31T22:29:34Z", "author": "William FH", "message": "langchain[patch]: Add warning in react agent (#26980)", "changed_files_if_available": 2, "additions": 8, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-10-31T21:15:46Z", "authored_date": "2024-10-31T21:15:46Z", "author": "Eugene Yurtsev", "message": "docs: fix more links (#27809)\n\nFix more broken links", "changed_files_if_available": 41, "additions": 77, "deletions": 77, "status": "SUCCESS"}, {"committed_date": "2024-10-31T20:52:00Z", "authored_date": "2024-10-31T20:52:00Z", "author": "Ant White", "message": "core: use friendlier names for duplicated nodes in mermaid output (#27747)\n\nThank you for contributing to LangChain!\r\n\r\n- [x] **PR title**: \"core: use friendlier names for duplicated nodes in\r\nmermaid output\"\r\n\r\n- **Description:** When generating the Mermaid visualization of a chain,\r\nif the chain had multiple nodes of the same type, the reid function\r\nwould replace their names with the UUID node_id. This made the generated\r\ngraph difficult to understand. This change deduplicates the nodes in a\r\nchain by appending an index to their names.\r\n- **Issue:** None\r\n- **Discussion:**\r\nhttps://github.com/langchain-ai/langchain/discussions/27714\r\n- **Dependencies:** None\r\n\r\n- [ ] **Add tests and docs**:  \r\n- Currently this functionality is not covered by unit tests, happy to\r\nadd tests if you'd like\r\n\r\n\r\n- [x] **Lint and test**: Run `make format`, `make lint` and `make test`\r\nfrom the root of the package(s) you've modified. See contribution\r\nguidelines for more: https://python.langchain.com/docs/contributing/\r\n\r\nAdditional guidelines:\r\n- Make sure optional dependencies are imported within a function.\r\n- Please do not add dependencies to pyproject.toml files (even optional\r\nones) unless they are required for unit tests.\r\n- Most PRs should not touch more than one package.\r\n- Changes should be backwards compatible.\r\n- If you are adding something to community, do not re-import it in\r\nlangchain.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of\r\nbaskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.\r\n\r\n# Example Code:\r\n```python\r\nfrom langchain_core.runnables import RunnablePassthrough\r\n\r\ndef fake_llm(prompt: str) -> str: # Fake LLM for the example\r\n    return \"completion\"\r\n\r\nrunnable = {\r\n    'llm1':  fake_llm,\r\n    'llm2':  fake_llm,\r\n} | RunnablePassthrough.assign(\r\n    total_chars=lambda inputs: len(inputs['llm1'] + inputs['llm2'])\r\n)\r\n\r\nprint(runnable.get_graph().draw_mermaid(with_styles=False))\r\n```\r\n\r\n# Before\r\n```mermaid\r\ngraph TD;\r\n\tParallel_llm1_llm2_Input --> 0b01139db5ed4587ad37964e3a40c0ec;\r\n\t0b01139db5ed4587ad37964e3a40c0ec --> Parallel_llm1_llm2_Output;\r\n\tParallel_llm1_llm2_Input --> a98d4b56bd294156a651230b9293347f;\r\n\ta98d4b56bd294156a651230b9293347f --> Parallel_llm1_llm2_Output;\r\n\tParallel_total_chars_Input --> Lambda;\r\n\tLambda --> Parallel_total_chars_Output;\r\n\tParallel_total_chars_Input --> Passthrough;\r\n\tPassthrough --> Parallel_total_chars_Output;\r\n\tParallel_llm1_llm2_Output --> Parallel_total_chars_Input;\r\n```\r\n\r\n# After\r\n```mermaid\r\ngraph TD;\r\n\tParallel_llm1_llm2_Input --> fake_llm_1;\r\n\tfake_llm_1 --> Parallel_llm1_llm2_Output;\r\n\tParallel_llm1_llm2_Input --> fake_llm_2;\r\n\tfake_llm_2 --> Parallel_llm1_llm2_Output;\r\n\tParallel_total_chars_Input --> Lambda;\r\n\tLambda --> Parallel_total_chars_Output;\r\n\tParallel_total_chars_Input --> Passthrough;\r\n\tPassthrough --> Parallel_total_chars_Output;\r\n\tParallel_llm1_llm2_Output --> Parallel_total_chars_Input;\r\n```", "changed_files_if_available": 3, "additions": 40, "deletions": 5, "status": "SUCCESS"}, {"committed_date": "2024-10-31T19:46:39Z", "authored_date": "2024-10-31T19:46:39Z", "author": "Eugene Yurtsev", "message": "docs: fix more broken links (#27806)\n\nFix some broken links", "changed_files_if_available": 18, "additions": 21, "deletions": 21, "status": "SUCCESS"}, {"committed_date": "2024-10-31T19:23:16Z", "authored_date": "2024-10-31T19:23:16Z", "author": "Neli Hateva", "message": "docs: Ontotext GraphDB QA Chain Update Documentation (Fix versions of libraries) (#27783)\n\n- **Description:** Update versions of libraries in the Ontotext GraphDB\r\nQA Chain Documentation\r\n - **Issue:** N/A\r\n - **Dependencies:** N/A\r\n - **Twitter handle:** @OntotextGraphDB", "changed_files_if_available": 1, "additions": 14, "deletions": 10, "status": "SUCCESS"}, {"committed_date": "2024-10-31T18:56:22Z", "authored_date": "2024-10-31T18:56:22Z", "author": "L", "message": "feat: add batch request support for text-embedding-v3 model (#26375)\n\nPR title: \u201clangchain: add batch request support for text-embedding-v3\r\nmodel\u201d\r\n\r\nPR message:\r\n\r\n\u2022 Description: This PR introduces batch request support for the\r\ntext-embedding-v3 model within LangChain. The new functionality allows\r\nusers to process multiple text inputs in a single request, improving\r\nefficiency and performance for high-volume applications.\r\n\t\u2022\tIssue: This PR addresses #<issue_number> (if applicable).\r\n\u2022 Dependencies: No new external dependencies are required for this\r\nchange.\r\n\u2022 Twitter handle: If announced on Twitter, please mention me at\r\n@yourhandle.\r\n\r\nAdd tests and docs:\r\n\r\n1. Added unit tests to cover the batch request functionality, ensuring\r\nit operates without requiring network access.\r\n2. Included an example notebook demonstrating the batch request feature,\r\nlocated in docs/docs/integrations.\r\n\r\nLint and test: All required formatting and linting checks have been\r\nperformed using make format and make lint. The changes have been\r\nverified with make test to ensure compatibility.\r\n\r\nAdditional notes:\r\n\r\n\t\u2022\tThe changes are fully backwards compatible.\r\n\u2022 No modifications were made to pyproject.toml, ensuring no new\r\ndependencies were added.\r\n\u2022 The update only affects the langchain package and does not involve\r\nother packages.\r\n\r\n---------\r\n\r\nCo-authored-by: Chester Curme <chester.curme@gmail.com>", "changed_files_if_available": 1, "additions": 7, "deletions": 2, "status": "SUCCESS"}, {"committed_date": "2024-10-31T18:47:25Z", "authored_date": "2024-10-31T18:47:25Z", "author": "putao520", "message": "fix \"WARNING: Received notification from DBMS server: {severity: WARN\u2026 (#27112)\n\n\u2026ING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning}\r\n{category: DEPRECATION} {title: This feature is deprecated and will be\r\nremoved in future versions.} {description: CALL subquery without a\r\nvariable scope clause is now deprecated.\" this warning\r\n\r\nThank you for contributing to LangChain!\r\n\r\n- [ ] **PR title**: \"package: description\"\r\n- Where \"package\" is whichever of langchain, community, core, etc. is\r\nbeing modified. Use \"docs: ...\" for purely docs changes, \"templates:\r\n...\" for template changes, \"infra: ...\" for CI changes.\r\n  - Example: \"community: add foobar LLM\"\r\n\r\n\r\n- [ ] **PR message**: ***Delete this entire checklist*** and replace\r\nwith\r\n    - **Description:** a description of the change\r\n    - **Issue:** the issue # it fixes, if applicable\r\n    - **Dependencies:** any dependencies required for this change\r\n- **Twitter handle:** if your PR gets announced, and you'd like a\r\nmention, we'll gladly shout you out!\r\n\r\n\r\n- [ ] **Add tests and docs**: If you're adding a new integration, please\r\ninclude\r\n1. a test for the integration, preferably unit tests that do not rely on\r\nnetwork access,\r\n2. an example notebook showing its use. It lives in\r\n`docs/docs/integrations` directory.\r\n\r\n\r\n- [ ] **Lint and test**: Run `make format`, `make lint` and `make test`\r\nfrom the root of the package(s) you've modified. See contribution\r\nguidelines for more: https://python.langchain.com/docs/contributing/\r\n\r\nAdditional guidelines:\r\n- Make sure optional dependencies are imported within a function.\r\n- Please do not add dependencies to pyproject.toml files (even optional\r\nones) unless they are required for unit tests.\r\n- Most PRs should not touch more than one package.\r\n- Changes should be backwards compatible.\r\n- If you are adding something to community, do not re-import it in\r\nlangchain.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of\r\nbaskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.\r\n\r\nCo-authored-by: putao520 <putao520@putao282.com>", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "FAILURE"}, {"committed_date": "2024-10-31T18:37:41Z", "authored_date": "2024-10-31T18:37:41Z", "author": "Ankan Mahapatra", "message": "Update word_document.py  |  Fixed metadata[\"source\"] for web paths (#27220)\n\nThe metadata[\"source\"] value for the web paths was being set to\r\ntemporary path (/tmp).\r\n\r\nFixed it by creating a new variable self.original_file_path, which will\r\nstore the original path.\r\n\r\nThank you for contributing to LangChain!\r\n\r\n- [ ] **PR title**: \"package: description\"\r\n- Where \"package\" is whichever of langchain, community, core, etc. is\r\nbeing modified. Use \"docs: ...\" for purely docs changes, \"templates:\r\n...\" for template changes, \"infra: ...\" for CI changes.\r\n  - Example: \"community: add foobar LLM\"\r\n\r\n\r\n- [ ] **PR message**: ***Delete this entire checklist*** and replace\r\nwith\r\n    - **Description:** a description of the change\r\n    - **Issue:** the issue # it fixes, if applicable\r\n    - **Dependencies:** any dependencies required for this change\r\n- **Twitter handle:** if your PR gets announced, and you'd like a\r\nmention, we'll gladly shout you out!\r\n\r\n\r\n- [ ] **Add tests and docs**: If you're adding a new integration, please\r\ninclude\r\n1. a test for the integration, preferably unit tests that do not rely on\r\nnetwork access,\r\n2. an example notebook showing its use. It lives in\r\n`docs/docs/integrations` directory.\r\n\r\n\r\n- [ ] **Lint and test**: Run `make format`, `make lint` and `make test`\r\nfrom the root of the package(s) you've modified. See contribution\r\nguidelines for more: https://python.langchain.com/docs/contributing/\r\n\r\nAdditional guidelines:\r\n- Make sure optional dependencies are imported within a function.\r\n- Please do not add dependencies to pyproject.toml files (even optional\r\nones) unless they are required for unit tests.\r\n- Most PRs should not touch more than one package.\r\n- Changes should be backwards compatible.\r\n- If you are adding something to community, do not re-import it in\r\nlangchain.\r\n\r\nIf no one reviews your PR within a few days, please @-mention one of\r\nbaskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.", "changed_files_if_available": 1, "additions": 2, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-10-31T18:36:02Z", "authored_date": "2024-10-31T18:36:02Z", "author": "Daniel Birn", "message": "community: fix @embeddingKey in azure cosmos db no sql (#27377)\n\nI will keep this PR as small as the changes made.\r\n\r\n**Description:** fixes a fatal bug syntax error in\r\nAzureCosmosDBNoSqlVectorSearch\r\n**Issue:** #27269 #25468", "changed_files_if_available": 1, "additions": 3, "deletions": 3, "status": "FAILURE"}, {"committed_date": "2024-10-31T18:27:05Z", "authored_date": "2024-10-31T18:27:05Z", "author": "Bagatur", "message": "integrations[patch]: bump core to 0.3.15 (#27805)", "changed_files_if_available": 15, "additions": 1453, "deletions": 1296, "status": "SUCCESS"}, {"committed_date": "2024-10-31T18:21:48Z", "authored_date": "2024-10-31T18:21:48Z", "author": "Erick Friis", "message": "docs: experimental case, use yq action (#27798)", "changed_files_if_available": 3, "additions": 26, "deletions": 16, "status": "SUCCESS"}, {"committed_date": "2024-10-31T18:14:06Z", "authored_date": "2024-10-31T18:14:06Z", "author": "W. Gustavo Cevallos", "message": "community: Update Polygon.io API (#27552)\n\n**Description:** \r\nUpdate the wrapper to support the Polygon API if not you get an error. I\r\nkeeped `STOCKBUSINESS` for retro-compatbility with older endpoints /\r\nother uses\r\nOld Code:\r\n```\r\n if status not in (\"OK\", \"STOCKBUSINESS\"):\r\n    raise ValueError(f\"API Error: {data}\")\r\n\r\n```\r\nAPI Respond:\r\n```\r\nAPI Error: {'results': {'P': 0.22, 'S': 0, 'T': 'ZOM', 'X': 5, 'p': 0.123, 'q': 0, 's': 200, 't': 1729614422813395456, 'x': 1, 'z': 1}, 'status': 'STOCKSBUSINESS', 'request_id': 'XXXXXX'}\r\n```\r\n\r\n- **Issue:** N/A Polygon API update\r\n- **Dependencies:** N/A\r\n- **Twitter handle:** @wgcv\r\n\r\n---------\r\n\r\nCo-authored-by: ccurme <chester.curme@gmail.com>", "changed_files_if_available": 1, "additions": 4, "deletions": 4, "status": "FAILURE"}, {"committed_date": "2024-10-31T18:07:17Z", "authored_date": "2024-10-31T18:07:17Z", "author": "Wang", "message": "community: [fix] add missing tool_calls kwargs of delta message in openai adapter (#27492)\n\n- **Description:** add missing tool_calls kwargs of delta message in\r\nopenai adapter, then tool call will work correctly via adapter's stream\r\nchat completion\r\n- **Issue:** Fixes\r\nhttps://github.com/langchain-ai/langchain/issues/25436\r\n- **Dependencies:** None", "changed_files_if_available": 1, "additions": 6, "deletions": 0, "status": "SUCCESS"}, {"committed_date": "2024-10-31T18:00:16Z", "authored_date": "2024-10-31T18:00:16Z", "author": "Tao Wang", "message": "community: Fix a validation error for MoonshotChat (#27801)\n\n- **Description:** Change `MoonshotCommon.client` type from\r\n`_MoonshotClient` to `Any`.\r\n- **Issue:** Fix the issue #27058\r\n- **Dependencies:** No\r\n- **Twitter handle:** TaoWang2218\r\n\r\nIn PR #17100, the implementation for Moonshot was added, which defined\r\ntwo classes:\r\n\r\n- `MoonshotChat(MoonshotCommon, ChatOpenAI)` in\r\n`langchain_community.chat_models.moonshot`;\r\n- Here, `validate_environment()` assigns **client** as\r\n`openai.OpenAI().chat.completions`\r\n- Note that **client** here is actually a member variable defined in\r\n`ChatOpenAI`;\r\n- `MoonshotCommon` in `langchain_community.llms.moonshot`;\r\n- And here, `validate_environment()` assigns **_client** as\r\n`_MoonshotClient`;\r\n- Note that this is the underscored **_client**, which is defined within\r\n`MoonshotCommon` itself;\r\n\r\nAt this time, there was no conflict between the two, one being `client`\r\nand the other `_client`.\r\n\r\nHowever, in PR #25878 which fixed #24390, `_client` in `MoonshotCommon`\r\nwas changed to `client`. Since then, a conflict in the definition of\r\n`client` has arisen between `MoonshotCommon` and `MoonshotChat`, which\r\ncaused `pydantic` validation error.\r\n\r\nTo fix this issue, the type of `client` in `MoonshotCommon` should be\r\nchanged to `Any`.\r\n\r\nSigned-off-by: Tao Wang <twang2218@gmail.com>", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "FAILURE"}, {"committed_date": "2024-10-31T17:56:43Z", "authored_date": "2024-10-31T17:56:43Z", "author": "Bagatur", "message": "core[patch]: update image util err msg (#27803)", "changed_files_if_available": 1, "additions": 6, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-10-31T17:35:02Z", "authored_date": "2024-10-31T17:35:02Z", "author": "Bagatur", "message": "core[patch]: Release 0.3.15 (#27802)", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-10-31T17:34:51Z", "authored_date": "2024-10-31T17:34:51Z", "author": "Bagatur", "message": "core[patch]: rm image loading (#27797)", "changed_files_if_available": 3, "additions": 35, "deletions": 73, "status": "SUCCESS"}, {"committed_date": "2024-10-31T16:56:44Z", "authored_date": "2024-10-31T16:56:44Z", "author": "ZhangShenao", "message": "Improvement [docs] Improve api docs (#27787)\n\n- Add missing param\r\n- Remove unused param\r\n\r\n---------\r\n\r\nCo-authored-by: Chester Curme <chester.curme@gmail.com>", "changed_files_if_available": 1, "additions": 1, "deletions": 1, "status": "SUCCESS"}, {"committed_date": "2024-10-31T16:44:35Z", "authored_date": "2024-10-31T16:44:35Z", "author": "Changyong Um", "message": "community[docs]: Add content for the Lora adapter in the VLLM page. (#27788)\n\n**Description:**\r\nI added code for lora_request in the community package, but I forgot to\r\nadd content to the VLLM page. So, I will do that now. #27731\r\n\r\n---------\r\n\r\nCo-authored-by: Um Changyong <changyong.um@sfa.co.kr>", "changed_files_if_available": 1, "additions": 29, "deletions": 0, "status": "SUCCESS"}, {"committed_date": "2024-10-31T16:37:41Z", "authored_date": "2024-10-31T16:37:41Z", "author": "ccurme", "message": "community: add AzureOpenAIWhisperParser (#27796)\n\nCommandeered from https://github.com/langchain-ai/langchain/pull/26757.\r\n\r\n---------\r\n\r\nCo-authored-by: Sheepsta300 <128811766+Sheepsta300@users.noreply.github.com>", "changed_files_if_available": 4, "additions": 513, "deletions": 10, "status": "SUCCESS"}, {"committed_date": "2024-10-31T14:19:09Z", "authored_date": "2024-10-31T14:19:09Z", "author": "ccurme", "message": "community[patch]: cap SQLAlchemy and update deps (#27792)\n\nSQLAlchemy 2.0.36 introduces a regression when creating a table in\r\nDuckDB.\r\n\r\nRelevant issues:\r\n- In SQLAlchemy repo (resolution is to update DuckDB):\r\nhttps://github.com/sqlalchemy/sqlalchemy/discussions/12011\r\n- In DuckDB repo (PR is open):\r\nhttps://github.com/Mause/duckdb_engine/issues/1128\r\n\r\nPlan is to track these issues and remove cap when resolved.", "changed_files_if_available": 2, "additions": 111, "deletions": 132, "status": "SUCCESS"}, {"committed_date": "2024-10-31T04:31:01Z", "authored_date": "2024-10-31T04:31:01Z", "author": "Erick Friis", "message": "infra: build api docs from package listing (#27774)", "changed_files_if_available": 4, "additions": 272, "deletions": 126, "status": "SUCCESS"}]